%%% use twocolumn and 10pt options with the asme2ej format
\documentclass[twocolumn,10pt]{asme2ej}

\usepackage{epsfig} %% for loading postscript figures
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{enumitem}
\usepackage{amsmath} % for "bmatrix" environment and "\dfrac" macro
\usepackage{relsize}
\usepackage{float}
\usepackage{courier}
\usepackage{xcolor}
\usepackage{fancyhdr}


\setlength{\parindent}{0pt}
\newcommand{\id}{\hspace{6 mm}}


%\raggedbottom

\title{Low-Cost Visible Light Spectral Imaging}

\author{Daniel W. Dichter
    \affiliation{
Independent Researcher\\
Cambridge, Massachusetts, U.S.A.\\
daniel.w.dichter@gmail.com\\
\\
\color{red}
\emph{\textbf{DRAFT: \today}}\\
\color{black}

    }	
}

\begin{document}

\maketitle

\pagestyle{fancy}

\begin{abstract}{\it Spectral imaging is an emerging technology for measuring spectral power distributions (SPDs) of electromagnetic radiation over a two-dimensional spatial domain. Within the visible light wavelength band, spectral imaging measures light and color with greater accuracy than conventional cameras. However, adoption of this technology is impeded by high cost and complexity. To address these barriers, a simple low-cost method is developed using unmodified commodity hardware --- primarily a DSLR camera and a set of narrow bandpass filters. The quantity of filters is strictly minimized to a total of seven, set by the dimensionality of SPDs, the spectral sensitivities of eyes and cameras, and commercial availability. Camera spectral sensitivity is measured using this same filter set, a color chart, a spectrophotometer, and noon daylight modeled as CIE D65. The RAW photo format is used to access unprocessed sensor data. Independent SPD measurements from each color channel are fused as a sensitivity-weighted average for efficient and continuous interpolation between color channels with a high signal-to-noise ratio. Images are reconstructed from SPDs with standard observer functions. The method is demonstrated with a Canon 650D camera, a set of Thorlabs one-inch narrow bandpass filters, an X-Rite ColorChecker chart, and a Spectro 1 spectrophotometer. Accuracy is verified by quantitative comparison against direct measurement. The total hardware cost is \$1,643 from scratch, or \$715 starting with a camera of known spectral sensitivity.
}
\end{abstract}

\section{Introduction}

\subsection{Background}

% Motivate spectral imaging generally

Color perception results from the interaction of an illuminant, optionally a reflective surface, and an observer. Humans are trichromats, having three-dimensional color perception, over the visible light wavelength spectrum of 400 to 700 nm. Various animal species are dichromats, tetrachromats, and so on, with differing visible light wavelength limits. Human color perception is significantly rank-deficient even within its wavelength limits, as shown in Section \ref{curve_reconstruction}.

% Overview of hyperspectral datacubes

\id Whereas conventional digital photography produces a three-dimensional RGB color image, spectral imaging produces an $k$-dimensional hyperspectral datacube (HSDC), typically with 10 $\leq$ $k$ $\leq$ 60; wavelength channels replace color channels. HSDCs are informationally complete and observer independent, providing a more accurate representation of color, and enabling greater optionality in subsequent image processing.

% Spectral scanning

\id Spectral scanning is the simplest of several methods of generating HSDCs, wherein a 1-channel intensity image is captured at a series of regularly-spaced, narrow, non-overlapping wavelength bands. These images are subsequently ``stacked'' to form the final HSDC. Though spatially high-resolution relative to other methods, spectral scanning experiences ``spectral smearing'' if the subjects or sensor move during the image capture process, due to the characteristically large temporal distribution of the images. By comparison, so-called ``single-shot'' methods use various diffraction techniques to capture the entire HSDC simultaneously, but at lower spatial resolution.

% Cameras

\id Commercial hyperspectral cameras typically cost at least \$15,000, whereas consumer cameras such as DSLRs cost as low as \$500-1,500. Consumer cameras are not capable of spectral imaging as-is, but various investigators have demonstrated this capability nonetheless with various hardware and software methods. All such methods account for the non-linear trichromate spectral sensitivity of the camera's Bayer filter and image sensor.

\subsection{Related Work}

Several authors have demonstrated spectral imaging with consumer cameras.

\id Cosentino \cite{Cosentino} used 12 bandpass filters and a consumer camera to produce HSDCs, comparing results favorably to a commercial hyperspectral camera. The method requires modification of the camera, the filters are of non-uniform properties, and the quantity of filters is larger than necessary.

\id Baek et al. \cite{Baek} developed a single-shot method using a custom prism objective for diffraction grating. Combined spatial and wavelength information is separated by detection of ``spectral cues'' present ``only around object edges''. The requirement for the presence of edges limits the scenes that may be captured, and leads to a sensitive dependence between scene and system accuracy.

\id Habel et al. \cite{Habel} similarly developed a single-shot diffraction grating method. The custom objective is large and complex, and the reconstructed images are limited to 120 x 120 pixels.

\id Oh et al. \cite{Oh} developed a method using three different synchronized digital cameras, exploiting small differences in their sensitivities. An image registration process is used to align images between cameras using planarity. Principal component analysis is performed on a spectral database of Munsell colors to create a low-dimension vector space for describing SPDs as linear combinations.

\id The method described in this paper is believed to be novel in its low cost, high spatial resolution, and exclusive use of unmodified commodity hardware.

\section{Methods}

\subsection{Dimensionality of Reflectance Spectra}

Parkkinen et al. \cite{Parkkinen} measured the reflectance spectra of 1,257 standard Munsell color chips over 400 to 700 nm. Noting that ``the components of a color spectrum are highly correlated'', the authors performed principal component analysis on these spectra, producing a set of reflectance eigenvectors. It was found that these spectra could be reconstructed as linear combinations of eight or fewer eigenvectors. This result implies that reflectance spectra are up to eight-dimensional over the visible light spectrum, with a characteristic wavelength resolution of approximately (700 nm - 400 nm) / 8 = 37.5 nm.

\subsection{Curve Reconstruction}
\label{curve_reconstruction}

Sampling an SPD by spectral scanning with narrow bandpass filters produces a ``sparse'' sample; the value of the SPD is measured only at certain regular intervals. In the intervals between measurements, the value of the SPD is not measured, but can be accurately inferred due to the limited dimensionality of SPDs. This process is modeled as a curve reconstruction problem, i.e.\ given a sparse sampling of an unknown curve, reconstruct the curve by means of an appropriate interpolation scheme such that the reconstructed curve matches a theoretical measured curve.

\id To determine the optimal filter quantity and interpolation scheme, two reflectance datasets are considered: the 8 eigenvectors developed by Parkkinen \cite{Parkkinen}, and the 24 reflectance spectra measured from an X-Rite ColorChecker Classic (2014) using a Spectro 1 spectrophotometer. The quality of the reconstruction is calculated as the residual sum of squares, multiplied by the wavelength resolution, divided by the quantity of samples in the dataset. This calculation is performed without an illuminant (i.e.\ directly on reflectance), and with CIE D65 representing typical noon daylight. This normalized error metric allows direct comparison between datasets. The filters are assumed to be of sufficiently narrow bandwidth that they measure at their exact center wavelength (CWL).

\id Table \ref{table_reconstruction} organizes these results into four subsets with a common illuminant and reflectance. The following observations are made:

\begin{enumerate}
  \item 30 nm resolution outperforms 40 nm resolution in all cases.
  \item With a 40 nm resolution, cubic interpolation is optimal.
  \item With a 30 nm resolution, cubic interpolation is at least near-optimal.
  \item Optimized error at 40 nm is 1-3x the optimized error at 30 nm, but both are small in an absolute sense.
  \item The inclusion (or exclusion) of an illuminant does not significantly affect the quality of the curve reconstruction; reflectance dominates.
\end{enumerate}

Thus, 40 nm resolution and cubic interpolation are used for curve reconstruction. Representative plots are shown in Figure \ref{colorchecker_reconstruction}.

\subsection{Filter Set Design}

\label{section_filters}

Manufacturers of narrow bandpass filters include Thorlabs, Edmund Optics, and MidOpt. Within the visible light spectrum, CWL is generally discretized as whole-number multiples of 10 nm, i.e.\ [400, 410, 420, ... 700] nm.

\id The centroid of the visible light spectrum may be defined at the wavelength corresponding to 50\% on the cumulative density function (CDF) of the sum of the CIE 2° tristimulus observer functions [$\mathrm{\bar{x}}, \mathrm{\bar{y}}, \mathrm{\bar{z}}$]. \cite{CVRL} Rounding to the nearest 10 nm per commercial availability, this centroid is 540 nm.

\id It can be shown that the wavelength range of 420 to 660 nm encompasses 97\% of the area under the CIE 2° and 10° observer functions, thus: \cite{CVRL}\\

$ \displaystyle \int_{\lambda = \textrm{420 nm}}^{\lambda = \textrm{660 nm}} ( \mathrm{\bar{x}}+\mathrm{\bar{y}}+\mathrm{\bar{z}} ) d\lambda \approx \int_{\lambda = -\infty}^{\lambda = \infty} ( \mathrm{\bar{x}}+\mathrm{\bar{y}}+\mathrm{\bar{z}} ) d\lambda $ \\

This range is also evenly divisible into 40 nm increments, and intersects the centroid of 540 nm.

\id The final specification is the full-width half max (FWHM), or bandwidth. As discussed in Section \ref{curve_reconstruction}, it is desirable to minimize FWHM so that measurements are wavelength-accurate to the CWL. The reduction in overall transmission associated with a low FWHM can be compensated by increasing the exposure, as discussed in Section \ref{photographic}.

\id The set of filters chosen are shown in Figures \ref{thorlabs_filter_transmission_spectra} and \ref{canon}, and have the following properties:\\

\begin{tabular}{l | l}
%\hline
Quantity & 7 \\
Manufacturer & Thorlabs \\
CWL & 420 to 660 nm \\
CWL Spacing & 40 nm \\
FWHM & 10 nm \\
Part Numbers & FB420-10, FB460-10, etc. \\
Diameter & 1'' \\
Cost, Total & \$686 (+\$29 case) \\
%\hline
\end{tabular}

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{thorlabs_filter_transmission_spectra.eps}
\caption{Thorlabs narrow bandpass filter transmission spectra, per manufacturer's datasheets. \cite{Thorlabs}}
\label{thorlabs_filter_transmission_spectra}
\end{figure}

\subsection{Camera Response Linearity}
\label{Camera Sensor Linearity}

RAW values reported from cameras may be thought of as photonic measurements. With simple under- and over-exposure experiments, it was found that pure black (i.e.\ zero photons) corresponds to RAW = 2048. In principle, saturation occurs at the maximum value permitted by the bit depth: $2^{14}$ = 16,384. But in practice, saturation was observed at values nearly as low as 12,000. Between these limits, response linearity was verified by photographing the ColorChecker chart under noon daylight while independently varying shutter duration and ISO. The trichromate mode of the \#19 white swatch was calculated for each photo as the measurement of interest.

\id These measurements are shown in Figure \ref{linearity_shutter_data}. For ideal linearity, the RAW value is proportional to the product of shutter duration and ISO, all else equal. Accordingly, an idealized RAW value can be calculated for each reported RAW value. This relationship can be expressed as a set of transfer functions, shown in Figure \ref{linearity_shutter_curves}. The shape of these transfer functions indicates that the sensor has a linear response up to saturation as expected. Similarly, varying ISO with a constant shutter duration exhibited near-perfect linearity (f/22, ISO 100-12,800, 1/2,000 sec).

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{linearity_shutter_data.eps}
\caption{Reported RAW values for \#19 white ColorChecker swatch in noon daylight, f/22, ISO 100, 1/4,000-1/30 sec.}
\label{linearity_shutter_data}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{linearity_shutter_curves.eps}
\caption{Transfer functions for camera photonic measurement, for data in Figure \ref{linearity_shutter_data}.}
\label{linearity_shutter_curves}
\end{figure}

\subsection{Camera Spectral Sensitivity}
\label{Camera_Spectral_Sensitivity}

Camera spectral sensitivity is calculated by photographing a ColorChecker chart through each filter under clear (cloudless) noon daylight modeled as CIE D65. Noon daylight was chosen as the illuminant for its roughly neutral SPD, availability of standard data, and easy access at no cost. Images were captured on 2021-02-21 at 12:22 pm in an open field in Cambridge, Massachusetts. Each swatch produces a unique SPD modeled as the element-wise product of its spectral reflectance with the CIE D65 illuminant. \cite{CVRL} Reflectance spectra were measured using a Spectro 1 spectrophotometer with a domain of 400 to 700 nm and a resolution of 10 nm. Three scans were performed and averaged for each swatch, with near-perfect repeatability across trials. These spectra were validated by calculating the CIEDE2000 color difference against the manufacturer's published Lab color values under CIE D50 illuminant with a 2° observer. \cite{X-Rite} The error for all 24 swatches was 1.39 ± 1.06 $\Delta$E, showing good agreement. Research has shown significant variance in ColorChecker spectra, with standard deviations of 0.1-9.1\% over 400-700 nm, though the manufacturer does not publish spectra or tolerances. \cite{BabelColor}

\id Assuming an ideal linear response as shown in Section \ref{Camera Sensor Linearity}, sensitivity may be described generally as:\\

$\mathrm{ Sensitivity = S = \dfrac{Value \ Measured}{Value \ Actual} } = \dfrac{V_M}{V_A}$ \\

$V_A = \mathlarger{\sum_{\lambda}} I(\lambda) \odot R(\lambda) \odot T(\lambda)$ \\

with: \\

\begin{tabular}{l | l}
$\lambda$ & Wavelength \\
I & Scene illuminant\\
R & Swatch reflectance \\
T & Filter transmission \\
$\odot$ & Element-wise multiplication \\
\end{tabular} \\

$V_M$ is calculated as the mode of the RAW values inside a square inset slightly from the swatch perimeter. Mode was chosen for its robustness against so-called hot/dead pixels that commonly appear in RAW images, particularly for longer exposures.

\id Sensitivity for all color channels and wavelengths can be calculated from any single swatch, as shown in Figure \ref{canon_650d_sensitivity}. These per-swatch sensitivity curves are fused as a weighted average using $V_M$. This has the effect of weighting calculated sensitivities in proportion to their signal-to-noise ratio.

\id The final result is a set of three sensitivity curves, $\left[ S_R(\lambda), \ S_G(\lambda), \ S_B(\lambda) \right]$. As shown in Figure \ref{camera_spectral_sensitivities}, this result is consistent with values from literature for similar Canon cameras. \cite{Jiang}

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{canon_650d_sensitivity.eps}
\caption{Non-dimensional trichromate spectral sensitivity of Canon 650D camera from ColorChecker under D65 illuminant. Faint colored lines correspond to individual swatches; solid black lines correspond to weighted averages for all swatches.}
\label{canon_650d_sensitivity}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{camera_spectral_sensitivities.eps}
\caption{Comparison of normalized sensitivities for various Canon cameras between this paper and literature. \cite{Jiang}}
\label{camera_spectral_sensitivities}
\end{figure}

\subsection{Photographic Aspects}
\label{photographic}

A prime lens, tripod, quick release plate, and remote shutter are used to minimize movement of the camera while capturing the photo stack. Because filter cost is proportional to filter area, the choice of lens is a significant means of cost reduction. The measurement of interest is the diameter of the objective at the outer end of the lens, as it sets the minimum filter diameter. For consumer-grade Canon EF lenses, this ranges from approximately 20 to 60 mm. The theoretical filter cost at these extremes differs by nearly an order of magnitude; $60^2 / 20^2 = 9$.

\id The lens selected has an outer objective diameter of 20 mm, a focal length of 40 mm, and an aperture of f/2.8. It is shown in Figure \ref{canon}.

\id The filters discussed in Section \ref{section_filters} are unthreaded, and used by resting them against the camera lens by hand. The lens is designed such that its glass optics are recessed from the exterior case against which the lenses rest. The filters are stored in a case in order of ascending wavelength, and cycled through in sequence manually to capture the photo stack.

\id Depending on the nature and luminance of the scene, typical camera settings are f/2.8-4, ISO 100-400, and 1/4 - 1/500 second. Bright exposures are required to compensate for the low transmission of the filters. The settings are collectively adjusted to ``expose to the right'', i.e.\ fully utilize the available set of values without saturating the upper limit, thereby maximizing the signal-to-noise ratio in the measured values.

\begin{figure}
\centering
\includegraphics[width=0.45\textwidth]{IMG_20210712_212507_GIMP.jpg}
\caption{Canon 650D camera with 40 mm prime EF lens, and set of Thorlabs narrow bandpass filters.}
\label{canon}
\end{figure}

\id The open-source \texttt{dcraw} utility is used to extract RAW values stored in the .CR2 file format. The modifier string \texttt{-D -4 -j -t 0} specifies that the extracted RAW values are unprocessed sensor measurements:\\

\begin{tabular}{l | l}
-D & No value scaling \\
-4 & Linear 16-bit \\
-j & No stretching or rotating pixels \\
-t 0 & No image rotation \\
\end{tabular} \\

The RAW sensor measurements are then demosaiced into R, G, B color channels with a Bayer filter pattern of \texttt{rggb}.

\subsection{SPDs from RAW Photos}

 By rearranging the general expression of sensitivity in Section \ref{Camera_Spectral_Sensitivity}: \\

 $V_A = \dfrac{V_M}{S}$ \\

Assuming a linear sensor response, $V_M \propto P$, with $P$ denoting the RAW photo value. By inspection, $V_A \propto SPD$. Filter transmission $T$ is accounted for as a factor acting on $S$, a property of the camera only. Using proportionality and non-dimensionality, this is rearranged and substituted as: \\

 $SPD = V_A = \dfrac{P}{ST}$ \\

The denominator $ST$ is most accurately and generally expressed as $S(\lambda) \cdot T(\lambda)$, rather than $S(\lambda=CWL) T(\lambda=CWL)$, i.e.\ a dot product over the wavelength domain, rather than a scalar product at the CWL.

\id At an arbitrary pixel and CWL, each color channel produces an independent SPD measurement, collectively given as: \\

 $SPD = \left[ \dfrac{P_R}{S_R \cdot T},\dfrac{P_G}{S_G \cdot T},\dfrac{P_B}{S_B \cdot T} \right] $ \\

These measurements are theoretically equal, but in practice differ as a result of various sources of error. They are fused as a sensitivity-weighted average: \\

$\overline{SPD} = \dfrac{1}{S_R+S_G+S_B} \left( \dfrac{P_R S_R}{S_R \cdot T} + \dfrac{P_G S_G}{S_G \cdot T} + \dfrac{P_B S_B}{S_B \cdot T} \right)$\\

Calculating $\overline{SPD}$ as a sensitivity-weighted average continuously interpolates between color channels as a function of wavelength. Since $S_R+S_G+S_B > 0$ for all $\lambda$, divide-by-zero is precluded. This formulation generalizes spatially by using matrices in place of scalars for $P$.

\id The HSDC is first calculated in a sparse fashion, only at the CWLs of the filters. The full (i.e.\ non-sparse) HSDC is then calculated by 3D cubic interpolation in the wavelength domain between the filter CWLs per Section \ref{curve_reconstruction}.

\section{Results}
\subsection{Validation}
\label{validation}

The method is validated by comparing ColorChecker SPDs, as measured by camera vs.\ a spectrophotometer, with the latter taken as ground truth. Because the two sets of curves, $SPD_{camera}$ and $SPD_{spectrophotometer}$, are non-dimensional, their ranges are aligned with a single scalar gain for comparative purposes, such that the sum of the residuals is zero. This scalar gain $\alpha$ is found by the bisection method such that:\\

$\mathlarger{ \sum_{\lambda}} ( \alpha SPD_{camera}- SPD_{spectrophotometer} )=0$. \\

Colors are generated from these SPDs according to standard tristimulus equations: \cite{CVRL} \cite{Lindbloom}\\

$X = \dfrac{1}{N} \mathlarger{ \sum_{\lambda}} \hspace{1 mm} \bar{x} \odot SPD(\lambda) \Delta \lambda$\\
$Y = \dfrac{1}{N} \mathlarger{ \sum_{\lambda}} \hspace{1 mm} \bar{y} \odot SPD(\lambda) \Delta \lambda$\\
$Z = \dfrac{1}{N} \mathlarger{ \sum_{\lambda}} \hspace{1 mm} \bar{z} \odot SPD(\lambda) \Delta \lambda$\\
$N = \mathlarger{ \sum_{\lambda}} \hspace{1 mm} \bar{y} \odot I(\lambda) \Delta \lambda$\\

The specific formulation for $SPD(\lambda)$ is given by:\\

\begin{tabular}{l l l}
$SPD_{camera}$ & $= SPD(\lambda)$ & (Emissive case) \\
$SPD_{spectrophotometer}$ & $= R(\lambda) \odot I(\lambda)$ & (Reflective case) \\
\end{tabular}\\

RGB and Lab colors are then calculated from these XYZ colors with D65 specified as the white point using standard conversion functions. \cite{Lindbloom} Color difference $\Delta$E is calculated using CIEDE2000.

\id Results are shown in Figure \ref{SPD_validation}. The color error for all swatches is 2.41 $\pm$ 1.61 $\Delta$ E. The primary outlier is \#19 white, which shows a good match in terms of normalized distribution, but a poor match in magnitude and thus brightness. Ruling out sensor nonlinearity and erroneous reflectance spectra per Sections \ref{Camera Sensor Linearity} and \ref{Camera_Spectral_Sensitivity}, this is best explained by spatially non-uniform scene illumination, amplified most by the uniquely high reflectance of the color white. Corroborating this, the SPDs of the matte black background behind the ColorChecker chart show a spatial luminance variance of roughly $\pm$ 5-8\%, which matches the SPD magnitude error.

\subsection{Images from HSDCs}

RGB images are generated from HSDCs using the equations in Section \ref{validation}. Since $N$ is undefined in the emissive case, a more general scaling method is necessary to translate non-dimensional SPDs to the dimensional color space of RGB. Accordingly, the image's value CDF is calculated and rescaled such that the image fully utilizes the color space with negligible saturation at both extreme ends. This is stated using typical parameters as:\\

\begin{tabular}{l l}
Value(CDF = 1\%) & = 5\%\\
Value(CDF = 99\%) & = 95\%\\
\end{tabular}\\

\clearpage

\onecolumn

\subsection{Reconstructed Images}

\begin{figure}[H]
\begin{centering}
  \includegraphics[height=0.55\linewidth]{colorchecker.jpg}
  \caption{Reconstructed image of ColorChecker chart under noon daylight; f/2.8, ISO 100, 1/400 sec.}
  \label{colorchecker_mesh}
  \end{centering}
\end{figure}

\begin{figure}[H]
\begin{centering}
  \includegraphics[height=0.6\linewidth]{colorchecker_SPDs.eps}
  \caption{SPD and reconstructed color at center of each swatch in Figure \ref{colorchecker_mesh}.}
  \label{colorchecker_SPDs}
    \end{centering}
\end{figure}

\clearpage

\begin{figure}[H]
\begin{centering}
  \includegraphics[height=0.55\linewidth]{broccoli_bottle_tomato.jpg}
  \caption{Reconstructed image of still life under evening horizon light; f/10, ISO 400, 1/4 sec.}
  \label{tomato_mesh}
  \end{centering}
\end{figure}

\begin{figure}[H]
\begin{centering}
  \includegraphics[height=0.6\linewidth]{broccoli_bottle_tomato.eps}
  \caption{SPDs and reconstructed colors sampled at a 70-node square mesh for the scene in Figure \ref{tomato_mesh}.}
  \label{tomato_SPDs}
  \end{centering}
\end{figure}

\clearpage

\begin{figure}[H]
\begin{centering}
  \includegraphics[height=0.55\linewidth]{vermont_path.jpg}
  \caption{Reconstructed image of Vermont landscape at sunset; f/2.8, ISO 200, 1/200 sec.}
  \label{path_mesh}
  \end{centering}
\end{figure}

\begin{figure}[H]
\begin{centering}
  \includegraphics[height=0.6\linewidth]{vermont_path.eps}
  \caption{SPDs and reconstructed colors sampled at a 70-node square mesh for the scene in Figure \ref{path_mesh}.}
  \label{path_SPDs}
  \end{centering}
\end{figure}

\clearpage

\begin{figure}[H]
\begin{centering}
  \includegraphics[height=0.55\linewidth]{truck.jpg}
  \caption{Reconstructed image of industrial scene at sunset; f/4, ISO 200, 1/60 sec.}
  \label{truck_mesh}
  \end{centering}
\end{figure}

\begin{figure}[H]
\begin{centering}
  \includegraphics[height=0.6\linewidth]{truck_SPDs.eps}
  \caption{SPDs and reconstructed colors sampled at a 70-node square mesh for the scene in Figure \ref{truck_mesh}.}
  \label{path_SPDs}
  \end{centering}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\twocolumn

\section{Discussion}

This paper demonstrates a method for visible light spectral imaging at less than 1/10 the cost of a commercial hyperspectral camera, primarily using a consumer camera and set of narrow bandpass filters. It employs sparse sampling and curve reconstruction to measure SPDs. Its results in terms of SPDs and reconstructed colors compare favorably to direct ground truth measurement.

\id Observer functions $[ \bar{x}, \bar{y}, \bar{z} ]$ have inherent limitations as the sole basis for generating RGB images from HSDCs. They model independent single-color perception only, and do not account for the the mutual influence of simultaneously-perceived colors. This deficiency is apparent in nontrivial scenes where the luminance spans several orders of magnitude, or the illuminant is significantly non-spectrally uniform, i.e.\ colored; examples include sunsets and indoor incandescent lighting. Literature is lacking in general numerical methods for describing the mutual perceptual influence of colors on each other.

\id Future work may include:

\begin{enumerate}
\item Refining the underlying assumptions and equations
\item Quantifying the mutual perceptual influence of colors
\item Reducing the diameter of the lens objective and filters 
\item Improving and/or automating the filter cycling
\end{enumerate}

\section{Acknowledgements}

The author gratefully recognizes the contributions of friends, family, and colleagues --- in particular, Eric Kirchner for color science and publication guidance, Trey Henderson for computational imaging, Evan Molinari for copyediting, and Michał Dichter for signal processing and project support.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 \begin{thebibliography}{12}

\bibitem{BabelColor}
{BabelColor. {The ColorChecker Pages}. Access 2021-08-01. https://www.babelcolor.com}

\bibitem{Baek}
{Baek, S.-H., Kim, I., Gutierrez, D., \& Kim, M. H. (2017). \emph{Compact Single-Shot Hyperspectral Imaging Using a Prism.} ACM Transactions on Graphics, 36(6), 1–12. https://doi.org/10.1145/3130800.3130896}

\bibitem{Cosentino}
{Cosentino, A. (2015). \emph{Multispectral Imaging System Using 12 Interference Filters for Mapping Pigments.} Conservar Património, 21, 25–38. https://doi.org/10.14568/cp2015005}

\bibitem{CVRL}
{Colour \& Vision Research Laboratory (n.d.). \emph{CVRL Main.} http://cvrl.ioo.ucl.ac.uk/index.htm.}

\bibitem{Habel}
{Habel, R., Kudenov, M., \& Wimmer, M. (2012). \emph{Practical Spectral Photography.} Computer Graphics Forum, 31(2pt2), 449–458. https://doi.org/10.1111/j.1467-8659.2012.03024.x}

\bibitem{Jiang}
{Jiang, J., Liu, D., Gu, J., \& Susstrunk, S. (2013). \emph{What is the Space of Spectral Sensitivity Functions for Digital Color Cameras?} 2013 IEEE Workshop on Applications of Computer Vision (WACV). https://doi.org/10.1109/wacv.2013.6475015}

\bibitem{Lindbloom}
{Lindbloom, B. J. (n.d.). \emph{Spectral Computation of XYZ.} http://www.brucelindbloom.com.}

\bibitem{Oh}
{Oh, S. W., Brown, M. S., Pollefeys, M., \& Kim, S. J. (2016). \emph{Do It Yourself Hyperspectral Imaging with Everyday Digital Cameras.} 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). https://doi.org/10.1109/cvpr.2016.270}

 \bibitem{Parkkinen} 
 {Parkkinen, J. P. S., Hallikainen, J., \& Jaaskelainen, T. (1989, February 1). \emph{Characteristic Spectra of Munsell Colors}. JOSA A. https://www.osapublishing.org/josaa/abstract.cfm?uri=josaa-6-2-318.}

\bibitem{Thorlabs}
{Thorlabs. \emph{UV/VIS Bandpass \& Laser Line Filters: 340 - 694.3 nm Center Wavelength}. Accessed 2020-10-19. https://www.thorlabs.com.}

\bibitem{X-Rite}
{X-Rite. \emph{Colorimetric values for ColorChecker family of targets}. 2019-04-11. https://xritephoto.com.}

\end{thebibliography}
 
 
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage 
\onecolumn
\section{Appendices}

\begin{figure}[H]
\begin{centering}
\includegraphics[width=0.90\textwidth]{colorchecker_reconstruction.eps}
\caption{Curve reconstruction of simulated non-dimensional ColorChecker SPDs, modeled as measured reflectance spectra under D65 illuminant, with cubic interpolation, seven samples, 40 nm resolution, over 420 to 660 nm.}
\label{colorchecker_reconstruction}
\end{centering}
\end{figure}

\begin{figure}[H]
\centering
  \includegraphics[width=0.90\linewidth]{SPD_validation.eps}
  \caption{Comparison of SPDs and colors as measured by spectrophotometer (solid, left) and camera (dashed, right). A single scalar gain is applied to align the magnitudes of the two sets of curves. Color error in CIEDE2000 is reported for each swatch. Plots are scaled 400 to 700 nm along x, and non-dimensional along y.}
  \label{SPD_validation}
\end{figure}


\begin{table}[t]
\begin{center}
\begin{tabular}{l l r l r}
\hline
\textbf{Reflectance Dataset} & \textbf{Illuminant} & \textbf{Resolution, nm} & \textbf{Interpolation Method} & \textbf{Error Metric} \\
\hline
Parkkinen & None & 30 & spline & 0.024  \\
Parkkinen & None & 30 & cubic  & 0.038  \\
Parkkinen & None & 30 & linear & 0.053  \\
Parkkinen & None & 40 & cubic  & 0.068  \\
Parkkinen & None & 40 & spline & 0.069  \\
Parkkinen & None & 40 & linear & 0.118  \\
\hline
ColorChecker & None & 30 & cubic  & 0.006  \\
ColorChecker & None & 30 & spline & 0.010  \\
ColorChecker & None & 40 & cubic  & 0.016  \\
ColorChecker & None & 30 & linear & 0.018  \\
ColorChecker & None & 40 & linear & 0.032  \\
ColorChecker & None & 40 & spline & 0.035  \\
\hline
Parkkinen & D65 & 30 & spline & 0.028  \\
Parkkinen & D65 & 30 & cubic  & 0.033  \\
Parkkinen & D65 & 30 & linear & 0.040  \\
Parkkinen & D65 & 40 & cubic  & 0.057  \\
Parkkinen & D65 & 40 & spline & 0.062  \\
Parkkinen & D65 & 40 & linear & 0.090  \\
\hline
ColorChecker & D65 & 30 & linear & 0.033  \\
ColorChecker & D65 & 40 & cubic  & 0.034  \\
ColorChecker & D65 & 30 & cubic  & 0.034  \\
ColorChecker & D65 & 30 & spline & 0.036  \\
ColorChecker & D65 & 40 & linear & 0.039  \\
ColorChecker & D65 & 40 & spline & 0.055  \\
\hline
\end{tabular}
\caption{Curve reconstruction quality as a function of dataset, illuminant, resolution, and interpolation method.}
\label{table_reconstruction}
\end{center}
\end{table}

\begin{table}[t]
\begin{center}
\begin{tabular}{l l r}
\textbf{Item} & \textbf{Vendor} & \textbf{Cost, \$} \\
\hline
Spectro 1 spectrophotometer       & Variable, Inc. &   325 \\
Canon 650D camera                 & eBay &             300 \\
Canon EF 40 mm prime lens         & Canon &            150 \\
Thorlabs FB420-10 1'' filter      & Thorlabs &         108 \\
Thorlabs FB460-10 1'' filter      & Thorlabs &         102 \\
Thorlabs FB500-10 1'' filter      & Thorlabs &         100 \\
Thorlabs FB540-10 1'' filter      & Thorlabs &         94  \\
Thorlabs FB580-10 1'' filter      & Thorlabs &         94  \\
Thorlabs FB620-10 1'' filter      & Thorlabs &         94  \\
Thorlabs FB660-10 1'' filter      & Thorlabs &         94  \\
Thorlabs BX0110 filter case  & Thorlabs &         29  \\
X-Rite ColorChecker Classic chart         & B\&H Photo Video & 80  \\
Velbon VideoMate II tripod        & eBay &             33  \\
Velbon QB-5RL quick release plate & Amazon &           17  \\
Neewer remote shutter             & Amazon &           23  \\
\hline
\textbf{Total, all items} & & 1,643 \\
\textbf{Total, filters only} & & 715 \\
\end{tabular}
\caption{Bill of materials.}
\label{materials}
\end{center}
\end{table}

\end{document}


